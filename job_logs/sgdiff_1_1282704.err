+ cd /gpfswork/rech/gtb/ukj95zg/SGDiff
+ srun python trainer.py --base config_vg.yaml -t --gpus 0,1
Global seed set to 23
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
Global seed set to 23
Global seed set to 23
initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2
Global seed set to 23
initializing ddp: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All DDP processes registered. Starting ddp with 2 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
/gpfsdswork/projects/rech/gtb/ukj95zg/miniconda3/envs/sgdiff/lib/python3.7/site-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.
  f"DataModule.{name} has already been called, so it will not be called again. "
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 2023-11-22T14-04-33_config_vg.
wandb: Tracking run with wandb version 0.15.12
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Set SLURM handle signals.
Set SLURM handle signals.

  | Name              | Type             | Params
-------------------------------------------------------
0 | model             | DiffusionWrapper | 395 M 
1 | model_ema         | LitEma           | 0     
2 | first_stage_model | VQModelInterface | 67.7 M
3 | cond_stage_model  | CGIPModel        | 13.2 M
-------------------------------------------------------
395 M     Trainable params
81.0 M    Non-trainable params
476 M     Total params
1,906.921 Total estimated model params size (MB)
Global seed set to 23
Global seed set to 23
/gpfsdswork/projects/rech/gtb/ukj95zg/miniconda3/envs/sgdiff/lib/python3.7/site-packages/pytorch_lightning/callbacks/lr_monitor.py:116: RuntimeWarning: You are using `LearningRateMonitor` callback with models that have no learning rate schedulers. Please see documentation for `configure_optimizers` method.
  RuntimeWarning,
[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/gpfsdswork/projects/rech/gtb/ukj95zg/miniconda3/envs/sgdiff/lib/python3.7/site-packages/torch/autograd/__init__.py:175: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 256, 1, 1], strides() = [256, 1, 256, 256]
bucket_view.sizes() = [256, 256, 1, 1], strides() = [256, 1, 1, 1] (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/torch/csrc/distributed/c10d/reducer.cpp:312.)
  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
/gpfsdswork/projects/rech/gtb/ukj95zg/miniconda3/envs/sgdiff/lib/python3.7/site-packages/torch/autograd/__init__.py:175: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 256, 1, 1], strides() = [256, 1, 256, 256]
bucket_view.sizes() = [256, 256, 1, 1], strides() = [256, 1, 1, 1] (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/torch/csrc/distributed/c10d/reducer.cpp:312.)
  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
/gpfsdswork/projects/rech/gtb/ukj95zg/miniconda3/envs/sgdiff/lib/python3.7/site-packages/pytorch_lightning/trainer/callback_hook.py:103: LightningDeprecationWarning: The signature of `Callback.on_train_epoch_end` has changed in v1.3. `outputs` parameter has been removed. Support for the old signature will be removed in v1.5
  "The signature of `Callback.on_train_epoch_end` has changed in v1.3."
Average Epoch time: 2108.38 seconds
Average Peak memory 19873.08MiB
Epoch 0, global step 1955: val/loss_simple_ema reached 0.18848 (best 0.18848), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000000.ckpt" as top 3
Average Epoch time: 2103.25 seconds
Average Peak memory 15071.39MiB
Epoch 1, global step 3911: val/loss_simple_ema reached 0.18402 (best 0.18402), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000001.ckpt" as top 3
Average Epoch time: 2103.26 seconds
Average Peak memory 15070.80MiB
Epoch 2, global step 5867: val/loss_simple_ema reached 0.17407 (best 0.17407), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000002.ckpt" as top 3
Average Epoch time: 2104.59 seconds
Average Peak memory 15071.39MiB
Epoch 3, global step 7823: val/loss_simple_ema reached 0.17746 (best 0.17407), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000003.ckpt" as top 3
Average Epoch time: 2104.50 seconds
Average Peak memory 15070.80MiB
Epoch 4, global step 9779: val/loss_simple_ema reached 0.17718 (best 0.17407), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000004.ckpt" as top 3
Average Epoch time: 2102.61 seconds
Average Peak memory 15071.39MiB
Epoch 5, global step 11735: val/loss_simple_ema reached 0.17193 (best 0.17193), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000005.ckpt" as top 3
Average Epoch time: 2105.34 seconds
Average Peak memory 15070.80MiB
Epoch 6, global step 13691: val/loss_simple_ema was not in top 3
Average Epoch time: 2102.66 seconds
Average Peak memory 15071.39MiB
Epoch 7, global step 15647: val/loss_simple_ema reached 0.17379 (best 0.17193), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000007.ckpt" as top 3
Average Epoch time: 2104.37 seconds
Average Peak memory 15070.80MiB
Epoch 8, global step 17603: val/loss_simple_ema reached 0.16908 (best 0.16908), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000008.ckpt" as top 3
Average Epoch time: 2106.70 seconds
Average Peak memory 15071.39MiB
Epoch 9, global step 19559: val/loss_simple_ema was not in top 3
Average Epoch time: 2110.68 seconds
Average Peak memory 15070.80MiB
Epoch 10, global step 21515: val/loss_simple_ema reached 0.16896 (best 0.16896), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000010.ckpt" as top 3
Average Epoch time: 2105.15 seconds
Average Peak memory 15071.39MiB
Epoch 11, global step 23471: val/loss_simple_ema reached 0.16843 (best 0.16843), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000011.ckpt" as top 3
Average Epoch time: 2109.63 seconds
Average Peak memory 15070.80MiB
Epoch 12, global step 25427: val/loss_simple_ema was not in top 3
Average Epoch time: 2108.67 seconds
Average Peak memory 15071.39MiB
Epoch 13, global step 27383: val/loss_simple_ema reached 0.16837 (best 0.16837), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000013.ckpt" as top 3
Average Epoch time: 2108.64 seconds
Average Peak memory 15070.80MiB
Epoch 14, global step 29339: val/loss_simple_ema was not in top 3
Average Epoch time: 2110.91 seconds
Average Peak memory 15071.39MiB
Epoch 15, global step 31295: val/loss_simple_ema was not in top 3
Average Epoch time: 2110.19 seconds
Average Peak memory 15070.80MiB
Epoch 16, global step 33251: val/loss_simple_ema reached 0.16816 (best 0.16816), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000016.ckpt" as top 3
Average Epoch time: 2105.56 seconds
Average Peak memory 15071.39MiB
Epoch 17, global step 35207: val/loss_simple_ema was not in top 3
Average Epoch time: 2110.35 seconds
Average Peak memory 15070.80MiB
Epoch 18, global step 37163: val/loss_simple_ema reached 0.16594 (best 0.16594), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000018.ckpt" as top 3
Average Epoch time: 2105.13 seconds
Average Peak memory 15071.39MiB
Epoch 19, global step 39119: val/loss_simple_ema was not in top 3
Average Epoch time: 2106.07 seconds
Average Peak memory 15070.80MiB
Epoch 20, global step 41075: val/loss_simple_ema was not in top 3
Average Epoch time: 2108.38 seconds
Average Peak memory 15071.39MiB
Epoch 21, global step 43031: val/loss_simple_ema reached 0.16492 (best 0.16492), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000021.ckpt" as top 3
Average Epoch time: 2109.72 seconds
Average Peak memory 15070.80MiB
Epoch 22, global step 44987: val/loss_simple_ema reached 0.16702 (best 0.16492), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000022.ckpt" as top 3
Average Epoch time: 2106.17 seconds
Average Peak memory 15071.39MiB
Epoch 23, global step 46943: val/loss_simple_ema was not in top 3
Average Epoch time: 2109.24 seconds
Average Peak memory 15070.80MiB
Epoch 24, global step 48899: val/loss_simple_ema was not in top 3
Average Epoch time: 2104.88 seconds
Average Peak memory 15071.39MiB
Epoch 25, global step 50855: val/loss_simple_ema reached 0.16484 (best 0.16484), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000025.ckpt" as top 3
Average Epoch time: 2109.15 seconds
Average Peak memory 15070.80MiB
Epoch 26, global step 52811: val/loss_simple_ema reached 0.16089 (best 0.16089), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000026.ckpt" as top 3
Average Epoch time: 2107.00 seconds
Average Peak memory 15071.39MiB
Epoch 27, global step 54767: val/loss_simple_ema was not in top 3
Average Epoch time: 2105.56 seconds
Average Peak memory 15070.80MiB
Epoch 28, global step 56723: val/loss_simple_ema was not in top 3
Average Epoch time: 2105.45 seconds
Average Peak memory 15071.39MiB
Epoch 29, global step 58679: val/loss_simple_ema reached 0.16399 (best 0.16089), saving model to "/gpfsdswork/projects/rech/gtb/ukj95zg/SGDiff/logs/2023-11-22T14-04-33_config_vg/checkpoints/epoch=000029.ckpt" as top 3
Average Epoch time: 2105.17 seconds
Average Peak memory 15070.80MiB
Epoch 30, global step 60635: val/loss_simple_ema was not in top 3
Average Epoch time: 2105.43 seconds
Average Peak memory 15071.39MiB
Epoch 31, global step 62591: val/loss_simple_ema was not in top 3
Average Epoch time: 2105.89 seconds
Average Peak memory 15070.80MiB
Epoch 32, global step 64547: val/loss_simple_ema was not in top 3
slurmstepd: error: *** STEP 1282704.0 ON r7i1n2 CANCELLED AT 2023-11-23T10:04:11 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 1282704 ON r7i1n2 CANCELLED AT 2023-11-23T10:04:11 DUE TO TIME LIMIT ***
